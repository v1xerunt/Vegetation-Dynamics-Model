{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:32:46.902880Z",
     "start_time": "2019-12-13T10:32:13.067095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import LSTM, Input, Dense, TimeDistributed, Concatenate, GRU\n",
    "import keras.backend as K\n",
    "from keras import regularizers, Model\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "import datetime\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:06.650643Z",
     "start_time": "2019-12-13T10:32:46.904750Z"
    }
   },
   "outputs": [],
   "source": [
    "data_1992 = pd.read_excel(r'./data/1992.xlsx', sheet_name='Export_Output1992')\n",
    "data_1992 = data_1992.drop('POINTID', axis=1)\n",
    "data_1992 = data_1992[data_1992['DEM']>=0]\n",
    "data_1992 = data_1992[data_1992['NDVI']>=0]\n",
    "data_1992 = data_1992[data_1992['lu']>=0]\n",
    "data_1992.loc[data_1992['gdp'] < 0, 'gdp'] = np.mean(data_1992[data_1992['gdp'] > 0]['gdp'])\n",
    "data_1992.loc[data_1992['pcp'] < 0, 'pcp'] = np.mean(data_1992[data_1992['pcp'] > 0]['pcp'])\n",
    "data_1992.loc[data_1992['tem'] < 0, 'tem'] = np.mean(data_1992[data_1992['tem'] > 0]['tem'])\n",
    "data_1992.loc[data_1992['pop'] < 0, 'pop'] = np.mean(data_1992[data_1992['pop'] > 0]['pop'])\n",
    "\n",
    "data_1998 = pd.read_excel(r'./data/1998.xlsx', sheet_name='Export_Output1998')\n",
    "data_1998 = data_1998.drop('POINTID', axis=1)\n",
    "data_1998 = data_1998[data_1998['DEM']>=0]\n",
    "data_1998 = data_1998[data_1998['NDVI']>=0]\n",
    "data_1998 = data_1998[data_1998['lu']>=0]\n",
    "data_1998.loc[data_1998['gdp'] < 0, 'gdp'] = np.mean(data_1998[data_1998['gdp'] > 0]['gdp'])\n",
    "data_1998.loc[data_1998['pcp'] < 0, 'pcp'] = np.mean(data_1998[data_1998['pcp'] > 0]['pcp'])\n",
    "data_1998.loc[data_1998['tem'] < 0, 'tem'] = np.mean(data_1998[data_1998['tem'] > 0]['tem'])\n",
    "data_1998.loc[data_1998['pop'] < 0, 'pop'] = np.mean(data_1998[data_1998['pop'] > 0]['pop'])\n",
    "\n",
    "data_2007 = pd.read_excel(r'./data/2007.xlsx', sheet_name='Export_Output2007')\n",
    "data_2007 = data_2007.drop('POINTID', axis=1)\n",
    "data_2007 = data_2007[data_2007['NDVI']>=0]\n",
    "data_2007 = data_2007[data_2007['DEM']>=0]\n",
    "data_2007 = data_2007[data_2007['lu']>=0]\n",
    "data_2007.loc[data_2007['gdp'] < 0, 'gdp'] = np.mean(data_2007[data_2007['gdp'] > 0]['gdp'])\n",
    "data_2007.loc[data_2007['pcp'] < 0, 'pcp'] = np.mean(data_2007[data_2007['pcp'] > 0]['pcp'])\n",
    "data_2007.loc[data_2007['tem'] < 0, 'tem'] = np.mean(data_2007[data_2007['tem'] > 0]['tem'])\n",
    "data_2007.loc[data_2007['pop'] < 0, 'pop'] = np.mean(data_2007[data_2007['pop'] > 0]['pop'])\n",
    "\n",
    "\n",
    "data_2018 = pd.read_excel(r'./data/2018.xlsx', sheet_name='Export_Output_2018')\n",
    "data_2018 = data_2018.drop('POINTID', axis=1)\n",
    "data_2018 = data_2018[data_2018['DEM']>=0]\n",
    "data_2018 = data_2018[data_2018['NDVI']>=0]\n",
    "data_2018 = data_2018[data_2018['lu']>=0]\n",
    "data_2018.loc[data_2018['gdp'] < 0, 'gdp'] = np.mean(data_2018[data_2018['gdp'] > 0]['gdp'])\n",
    "data_2018.loc[data_2018['pcp'] < 0, 'pcp'] = np.mean(data_2018[data_2018['pcp'] > 0]['pcp'])\n",
    "data_2018.loc[data_2018['tem'] < 0, 'tem'] = np.mean(data_2018[data_2018['tem'] > 0]['tem'])\n",
    "data_2018.loc[data_2018['pop'] < 0, 'pop'] = np.mean(data_2018[data_2018['pop'] > 0]['pop'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:26.760402Z",
     "start_time": "2019-12-13T10:33:06.652636Z"
    }
   },
   "outputs": [],
   "source": [
    "#Original data point\n",
    "data_dict1992 = dict()\n",
    "data_dict1998 = dict()\n",
    "data_dict2007 = dict()\n",
    "data_dict2018 = dict()\n",
    "\n",
    "for index,row in data_1992.iterrows():\n",
    "    cur_id = (int(row['X']),int(row['Y']))\n",
    "    data_dict1992[cur_id] = {}\n",
    "    data_dict1992[cur_id]['year'] = 1992\n",
    "    data_dict1992[cur_id]['x'] = cur_id[0]\n",
    "    data_dict1992[cur_id]['y'] = cur_id[1]\n",
    "    data_dict1992[cur_id]['height'] = row['DEM']\n",
    "    data_dict1992[cur_id]['dis'] = row['MEAN_NEAR_D']\n",
    "    data_dict1992[cur_id]['usage'] = row['lu']\n",
    "    data_dict1992[cur_id]['gdp'] = row['gdp']\n",
    "    data_dict1992[cur_id]['pcp'] = row['pcp']\n",
    "    data_dict1992[cur_id]['tem'] = row['tem']\n",
    "    data_dict1992[cur_id]['pop'] = row['pop']\n",
    "    data_dict1992[cur_id]['ndvi'] = row['NDVI']\n",
    "\n",
    "for index,row in data_1998.iterrows():\n",
    "    cur_id = (int(row['X']),int(row['Y']))\n",
    "    data_dict1998[cur_id] = {}\n",
    "    data_dict1998[cur_id]['year'] = 1998\n",
    "    data_dict1998[cur_id]['x'] = cur_id[0]\n",
    "    data_dict1998[cur_id]['y'] = cur_id[1]\n",
    "    data_dict1998[cur_id]['height'] = row['DEM']\n",
    "    data_dict1998[cur_id]['dis'] = row['MIN_NEAR_D']\n",
    "    data_dict1998[cur_id]['usage'] = row['lu']\n",
    "    data_dict1998[cur_id]['gdp'] = row['gdp']\n",
    "    data_dict1998[cur_id]['pcp'] = row['pcp']\n",
    "    data_dict1998[cur_id]['tem'] = row['tem']\n",
    "    data_dict1998[cur_id]['pop'] = row['pop']\n",
    "    data_dict1998[cur_id]['ndvi'] = row['NDVI']\n",
    "\n",
    "for index,row in data_2007.iterrows():\n",
    "    cur_id = (int(row['X']),int(row['Y']))\n",
    "    data_dict2007[cur_id] = {}\n",
    "    data_dict2007[cur_id]['year'] = 2007\n",
    "    data_dict2007[cur_id]['x'] = cur_id[0]\n",
    "    data_dict2007[cur_id]['y'] = cur_id[1]\n",
    "    data_dict2007[cur_id]['height'] = row['DEM']\n",
    "    data_dict2007[cur_id]['dis'] = row['MIN_NEAR_D']\n",
    "    data_dict2007[cur_id]['usage'] = row['lu']\n",
    "    data_dict2007[cur_id]['gdp'] = row['gdp']\n",
    "    data_dict2007[cur_id]['pcp'] = row['pcp']\n",
    "    data_dict2007[cur_id]['tem'] = row['tem']\n",
    "    data_dict2007[cur_id]['pop'] = row['pop']\n",
    "    data_dict2007[cur_id]['ndvi'] = row['NDVI']\n",
    "\n",
    "for index,row in data_2018.iterrows():\n",
    "    cur_id = (int(row['X']),int(row['Y']))\n",
    "    data_dict2018[cur_id] = {}\n",
    "    data_dict2018[cur_id]['year'] = 2018\n",
    "    data_dict2018[cur_id]['x'] = cur_id[0]\n",
    "    data_dict2018[cur_id]['y'] = cur_id[1]\n",
    "    data_dict2018[cur_id]['height'] = row['DEM']\n",
    "    data_dict2018[cur_id]['dis'] = row['MIN_NEAR_D']\n",
    "    data_dict2018[cur_id]['usage'] = row['lu']\n",
    "    data_dict2018[cur_id]['gdp'] = row['gdp']\n",
    "    data_dict2018[cur_id]['pcp'] = row['pcp']\n",
    "    data_dict2018[cur_id]['tem'] = row['tem']\n",
    "    data_dict2018[cur_id]['pop'] = row['pop']\n",
    "    data_dict2018[cur_id]['ndvi'] = row['NDVI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:27.405719Z",
     "start_time": "2019-12-13T10:33:26.762397Z"
    }
   },
   "outputs": [],
   "source": [
    "#Merge data\n",
    "data_dict = dict()\n",
    "for each_id in data_dict1992:\n",
    "    data_dict[each_id] = {}\n",
    "    data_dict[each_id] = {}\n",
    "    data_dict[each_id]['year'] = [1992]\n",
    "    data_dict[each_id]['x'] = each_id[0]\n",
    "    data_dict[each_id]['y'] = each_id[1]\n",
    "    data_dict[each_id]['height'] = data_dict1992[each_id]['height']\n",
    "    data_dict[each_id]['dis'] = [data_dict1992[each_id]['dis']]\n",
    "    data_dict[each_id]['ndvi'] = [data_dict1992[each_id]['ndvi']]\n",
    "    data_dict[each_id]['usage'] = [data_dict1992[each_id]['usage']]\n",
    "    data_dict[each_id]['gdp'] = [data_dict1992[each_id]['gdp']]\n",
    "    data_dict[each_id]['pcp'] = [data_dict1992[each_id]['pcp']]\n",
    "    data_dict[each_id]['tem'] = [data_dict1992[each_id]['tem']]\n",
    "    data_dict[each_id]['pop'] = [data_dict1992[each_id]['pop']]\n",
    "    \n",
    "for each_id in data_dict1998:\n",
    "    if each_id in data_dict:\n",
    "        data_dict[each_id]['year'].append(1998)\n",
    "        data_dict[each_id]['dis'] .append(data_dict1998[each_id]['dis'])\n",
    "        data_dict[each_id]['ndvi'].append(data_dict1998[each_id]['ndvi'])\n",
    "        data_dict[each_id]['usage'].append(data_dict1998[each_id]['usage'])\n",
    "        data_dict[each_id]['gdp'].append(data_dict1998[each_id]['gdp'])\n",
    "        data_dict[each_id]['pcp'].append(data_dict1998[each_id]['pcp'])\n",
    "        data_dict[each_id]['tem'].append(data_dict1998[each_id]['tem'])\n",
    "        data_dict[each_id]['pop'].append(data_dict1998[each_id]['pop'])\n",
    "    else:\n",
    "        data_dict[each_id] = {}\n",
    "        data_dict[each_id] = {}\n",
    "        data_dict[each_id]['year'] = [1998]\n",
    "        data_dict[each_id]['x'] = each_id[0]\n",
    "        data_dict[each_id]['y'] = each_id[1]\n",
    "        data_dict[each_id]['height'] = data_dict1998[each_id]['height']\n",
    "        data_dict[each_id]['dis'] = [data_dict1998[each_id]['dis']]\n",
    "        data_dict[each_id]['ndvi'] = [data_dict1998[each_id]['ndvi']]\n",
    "        data_dict[each_id]['usage'] = [data_dict1998[each_id]['usage']]\n",
    "        data_dict[each_id]['gdp'] = [data_dict1998[each_id]['gdp']]\n",
    "        data_dict[each_id]['pcp'] = [data_dict1998[each_id]['pcp']]\n",
    "        data_dict[each_id]['tem'] = [data_dict1998[each_id]['tem']]\n",
    "        data_dict[each_id]['pop'] = [data_dict1998[each_id]['pop']]\n",
    "    \n",
    "for each_id in data_dict2007:\n",
    "    if each_id in data_dict:\n",
    "        data_dict[each_id]['year'].append(2007)\n",
    "        data_dict[each_id]['dis'] .append(data_dict2007[each_id]['dis'])\n",
    "        data_dict[each_id]['ndvi'].append(data_dict2007[each_id]['ndvi'])\n",
    "        data_dict[each_id]['usage'].append(data_dict2007[each_id]['usage'])\n",
    "        data_dict[each_id]['gdp'].append(data_dict2007[each_id]['gdp'])\n",
    "        data_dict[each_id]['pcp'].append(data_dict2007[each_id]['pcp'])\n",
    "        data_dict[each_id]['tem'].append(data_dict2007[each_id]['tem'])\n",
    "        data_dict[each_id]['pop'].append(data_dict2007[each_id]['pop'])\n",
    "    else:\n",
    "        data_dict[each_id] = {}\n",
    "        data_dict[each_id] = {}\n",
    "        data_dict[each_id]['year'] = [2007]\n",
    "        data_dict[each_id]['x'] = each_id[0]\n",
    "        data_dict[each_id]['y'] = each_id[1]\n",
    "        data_dict[each_id]['height'] = data_dict2007[each_id]['height']\n",
    "        data_dict[each_id]['dis'] = [data_dict2007[each_id]['dis']]\n",
    "        data_dict[each_id]['ndvi'] = [data_dict2007[each_id]['ndvi']]\n",
    "        data_dict[each_id]['usage'] = [data_dict2007[each_id]['usage']]\n",
    "        data_dict[each_id]['gdp'] = [data_dict2007[each_id]['gdp']]\n",
    "        data_dict[each_id]['pcp'] = [data_dict2007[each_id]['pcp']]\n",
    "        data_dict[each_id]['tem'] = [data_dict2007[each_id]['tem']]\n",
    "        data_dict[each_id]['pop'] = [data_dict2007[each_id]['pop']]\n",
    "        \n",
    "for each_id in data_dict2018:\n",
    "    if each_id in data_dict:\n",
    "        data_dict[each_id]['year'].append(2018)\n",
    "        data_dict[each_id]['dis'] .append(data_dict2018[each_id]['dis'])\n",
    "        data_dict[each_id]['ndvi'].append(data_dict2018[each_id]['ndvi'])\n",
    "        data_dict[each_id]['usage'].append(data_dict2018[each_id]['usage'])\n",
    "        data_dict[each_id]['gdp'].append(data_dict2018[each_id]['gdp'])\n",
    "        data_dict[each_id]['pcp'].append(data_dict2018[each_id]['pcp'])\n",
    "        data_dict[each_id]['tem'].append(data_dict2018[each_id]['tem'])\n",
    "        data_dict[each_id]['pop'].append(data_dict2018[each_id]['pop'])\n",
    "    else:\n",
    "        data_dict[each_id] = {}\n",
    "        data_dict[each_id] = {}\n",
    "        data_dict[each_id]['year'] = [2018]\n",
    "        data_dict[each_id]['x'] = each_id[0]\n",
    "        data_dict[each_id]['y'] = each_id[1]\n",
    "        data_dict[each_id]['height'] = data_dict2018[each_id]['height']\n",
    "        data_dict[each_id]['dis'] = [data_dict2018[each_id]['dis']]\n",
    "        data_dict[each_id]['ndvi'] = [data_dict2018[each_id]['ndvi']]\n",
    "        data_dict[each_id]['usage'] = [data_dict2018[each_id]['usage']]\n",
    "        data_dict[each_id]['gdp'] = [data_dict2018[each_id]['gdp']]\n",
    "        data_dict[each_id]['pcp'] = [data_dict2018[each_id]['pcp']]\n",
    "        data_dict[each_id]['tem'] = [data_dict2018[each_id]['tem']]\n",
    "        data_dict[each_id]['pop'] = [data_dict2018[each_id]['pop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:32.420513Z",
     "start_time": "2019-12-13T10:33:27.407643Z"
    }
   },
   "outputs": [],
   "source": [
    "soil_data = pd.read_excel(r'./data/soil.xlsx', sheet_name='soil')\n",
    "for index,row in soil_data.iterrows():\n",
    "    cur_id = (int(row['X']),int(row['Y']))\n",
    "    if cur_id not in data_dict:\n",
    "        continue\n",
    "    else:\n",
    "        data_dict[cur_id]['soil'] = int(row['soil_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:32.553133Z",
     "start_time": "2019-12-13T10:33:32.422507Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate one-hot label\n",
    "soil_list = []\n",
    "usage_list = []\n",
    "for each_id in data_dict:\n",
    "    for i in range(len(data_dict[each_id]['year'])):\n",
    "        if int(data_dict[each_id]['usage'][i]) not in usage_list:\n",
    "            usage_list.append(int(data_dict[each_id]['usage'][i]))\n",
    "    if 'soil' not in data_dict[each_id]:\n",
    "        continue\n",
    "    if int(data_dict[each_id]['soil']) not in soil_list:\n",
    "        soil_list.append(int(data_dict[each_id]['soil']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:32.660843Z",
     "start_time": "2019-12-13T10:33:32.555125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 35 201 26677 4778\n"
     ]
    }
   ],
   "source": [
    "counter_1,counter_2,counter_3,counter_4,counter_5 = 0,0,0,0,0\n",
    "err_list = []\n",
    "for each_id in data_dict:\n",
    "    if 'soil' not in data_dict[each_id]:\n",
    "        err_list.append(each_id)\n",
    "        counter_5+=1\n",
    "        continue\n",
    "    if 0 in data_dict[each_id]['dis']:\n",
    "        err_list.append(each_id)\n",
    "        continue\n",
    "    if len(data_dict[each_id]['year']) == 1:\n",
    "        counter_1+=1\n",
    "        err_list.append(each_id)\n",
    "    elif len(data_dict[each_id]['year']) == 2:\n",
    "        counter_2+=1\n",
    "        err_list.append(each_id)\n",
    "    elif len(data_dict[each_id]['year']) == 3:\n",
    "        counter_3+=1\n",
    "        err_list.append(each_id)\n",
    "    elif len(data_dict[each_id]['year']) == 4:\n",
    "        counter_4+=1\n",
    "    else:\n",
    "        raise(ValueError)\n",
    "print(counter_1,counter_2,counter_3,counter_4,counter_5)\n",
    "for each_id in err_list:\n",
    "    del data_dict[each_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:33.054818Z",
     "start_time": "2019-12-13T10:33:32.664833Z"
    }
   },
   "outputs": [],
   "source": [
    "soil_cnt = len(soil_list)\n",
    "usage_cnt = len(usage_list)\n",
    "\n",
    "for each_id in data_dict:\n",
    "    cur_onehot = np.zeros(soil_cnt)\n",
    "    cur_onehot[soil_list.index(int(data_dict[each_id]['soil']))] = 1\n",
    "    data_dict[each_id]['soil'] = cur_onehot\n",
    "    for i in range(len(data_dict[each_id]['year'])):\n",
    "        cur_onehot = np.zeros(usage_cnt)\n",
    "        cur_onehot[usage_list.index(int(data_dict[each_id]['usage'][i]))] = 1\n",
    "        data_dict[each_id]['usage'][i] = cur_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:35.420464Z",
     "start_time": "2019-12-13T10:33:33.056783Z"
    }
   },
   "outputs": [],
   "source": [
    "dynamic = []\n",
    "static = []\n",
    "loc_id = []\n",
    "y = []\n",
    "\n",
    "dynamic_feature = ['ndvi','dis','gdp','pcp','tem','pop','usage']\n",
    "static_feature = ['x','y','height','soil']\n",
    "\n",
    "for each_id in data_dict:\n",
    "    cur_static = []\n",
    "    cur_dynamic = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        tmp = []\n",
    "        for each_feature in dynamic_feature:\n",
    "            if each_feature == 'usage':\n",
    "                tmp += list(data_dict[each_id][each_feature][i])\n",
    "            else:\n",
    "                tmp.append(data_dict[each_id][each_feature][i])\n",
    "        cur_dynamic.append(tmp)\n",
    "    cur_dynamic = np.array(cur_dynamic)\n",
    "    \n",
    "    for i in range(4):\n",
    "        tmp = []\n",
    "        for each_feature in static_feature:\n",
    "            if each_feature == 'soil':\n",
    "                tmp += list(data_dict[each_id][each_feature])\n",
    "            else:\n",
    "                tmp.append(data_dict[each_id][each_feature])\n",
    "        cur_static.append(tmp)\n",
    "    cur_static = np.array(cur_static)\n",
    "    \n",
    "    dynamic.append(cur_dynamic)\n",
    "    static.append(cur_static)\n",
    "    y.append(np.expand_dims(np.array(data_dict[each_id]['ndvi'])[1:], axis=-1))\n",
    "    loc_id.append(each_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:39.072693Z",
     "start_time": "2019-12-13T10:33:35.422456Z"
    }
   },
   "outputs": [],
   "source": [
    "dynamic_transform = []\n",
    "static_transform = []\n",
    "y_transform = []\n",
    "\n",
    "for each_id in range(len(static)):\n",
    "    for each_year in range(4):\n",
    "        dynamic_transform.append(dynamic[each_id][each_year])\n",
    "        static_transform.append(static[each_id][each_year])\n",
    "\n",
    "dynamic_transform = np.array(dynamic_transform)\n",
    "static_transform = np.array(static_transform)\n",
    "\n",
    "dynamic_scaler = sklearn.preprocessing.StandardScaler()\n",
    "static_scaler = sklearn.preprocessing.StandardScaler()\n",
    "dynamic_scaler = dynamic_scaler.fit(dynamic_transform)\n",
    "static_scaler = static_scaler.fit(static_transform)\n",
    "\n",
    "for each_id in range(len(static)):\n",
    "    dynamic[each_id] = dynamic_scaler.transform(dynamic[each_id])\n",
    "    static[each_id] = static_scaler.transform(static[each_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:39.221295Z",
     "start_time": "2019-12-13T10:33:39.075686Z"
    }
   },
   "outputs": [],
   "source": [
    "dynamic = np.array(dynamic)\n",
    "static = np.array(static)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:39.456667Z",
     "start_time": "2019-12-13T10:33:39.223291Z"
    }
   },
   "outputs": [],
   "source": [
    "all_ind = list(range(len(static)))\n",
    "train_ind, test_ind = train_test_split(all_ind, test_size=0.1, random_state=12345)\n",
    "train_ind, valid_ind = train_test_split(train_ind, test_size=0.1, random_state=12345)\n",
    "\n",
    "dynamic_train = []\n",
    "dynamic_valid = []\n",
    "dynamic_test = []\n",
    "static_train = []\n",
    "static_valid = []\n",
    "static_test = []\n",
    "label_train = []\n",
    "label_valid = []\n",
    "label_test = []\n",
    "\n",
    "for ind in train_ind:\n",
    "    dynamic_train.append(dynamic[ind][:-1])\n",
    "    static_train.append(static[ind][:-1])\n",
    "    label_train.append(y[ind])\n",
    "\n",
    "for ind in valid_ind:\n",
    "    dynamic_valid.append(dynamic[ind][:-1])\n",
    "    static_valid.append(static[ind][:-1])\n",
    "    label_valid.append(y[ind])\n",
    "\n",
    "for ind in test_ind:\n",
    "    dynamic_test.append(dynamic[ind])\n",
    "    static_test.append(static[ind])\n",
    "    label_test.append(y[ind])\n",
    "    \n",
    "dynamic_train = np.array(dynamic_train)\n",
    "dynamic_valid = np.array(dynamic_valid)\n",
    "dynamic_test = np.array(dynamic_test)\n",
    "static_train = np.array(static_train)\n",
    "static_valid = np.array(static_valid)\n",
    "static_test = np.array(static_test)\n",
    "label_train = np.array(label_train)\n",
    "label_valid = np.array(label_valid)\n",
    "label_test = np.array(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:39.465643Z",
     "start_time": "2019-12-13T10:33:39.458661Z"
    }
   },
   "outputs": [],
   "source": [
    "def det_coeff(y_true, y_pred):\n",
    "    u = K.sum(K.square(y_true - y_pred))\n",
    "    v = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return K.ones_like(v) - (u / v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:39.477611Z",
     "start_time": "2019-12-13T10:33:39.469633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21608, 3, 1)\n",
      "(21608, 3, 16)\n",
      "(21608, 3, 25)\n"
     ]
    }
   ],
   "source": [
    "print(label_train.shape)\n",
    "print(static_train.shape)\n",
    "print(dynamic_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:41.042454Z",
     "start_time": "2019-12-13T10:33:39.480603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\ProgramFiles\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_states (InputLayer)       (None, None, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, None, 16)     2016        input_states[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_statics (InputLayer)      (None, None, 16)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concat2 (Concatenate)           (None, None, 32)     0           gru[0][0]                        \n",
      "                                                                 input_statics[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (TimeDistributed)         (None, None, 8)      264         concat2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (TimeDistributed)        (None, None, 1)      9           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 2,289\n",
      "Trainable params: 2,289\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    feature_size = 25\n",
    "    static_size = 16\n",
    "    rnn_size = 16\n",
    "    l2_regular = regularizers.l2(1e-3)\n",
    "    \n",
    "    input_states = Input(shape=(None, feature_size), name='input_states')\n",
    "    input_static = Input(shape=(None, static_size), name='input_statics')\n",
    "    \n",
    "    gru = GRU(rnn_size, activation='tanh', name='gru', kernel_regularizer=l2_regular, return_sequences=True)(input_states) \n",
    "    concat_2 = Concatenate(name='concat2')([gru, input_static])\n",
    "    dense = TimeDistributed(Dense(8, activation='relu', kernel_regularizer=l2_regular), name='dense')(concat_2)\n",
    "    output = TimeDistributed(Dense(1, kernel_regularizer=l2_regular, activation='relu'), name='output')(dense)\n",
    "    model = Model([input_states, input_static], output)\n",
    "    opt = keras.optimizers.Adam(lr=1e-3)\n",
    "    model.compile(loss='mean_squared_error',optimizer=opt,  metrics=['mse',det_coeff])\n",
    "    return model\n",
    "print(create_model().summary())\n",
    "model_test = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_coeff: 0.6211 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6366\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.00427\n",
      "Epoch 228/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0036 - det_coeff: 0.6222 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6390\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.00427 to 0.00427, saving model to ./trained_weights/model\n",
      "Epoch 229/300\n",
      "21608/21608 [==============================] - 0s 10us/step - loss: 0.0043 - mean_squared_error: 0.0036 - det_coeff: 0.6214 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6368\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.00427\n",
      "Epoch 230/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0043 - mean_squared_error: 0.0036 - det_coeff: 0.6219 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6392\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.00427 to 0.00426, saving model to ./trained_weights/model\n",
      "Epoch 231/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0036 - det_coeff: 0.6196 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6393\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.00426\n",
      "Epoch 232/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0036 - det_coeff: 0.6228 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6406\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.00426 to 0.00425, saving model to ./trained_weights/model\n",
      "Epoch 233/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0036 - det_coeff: 0.6219 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6399\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.00425\n",
      "Epoch 234/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6231 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6379\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.00425\n",
      "Epoch 235/300\n",
      "21608/21608 [==============================] - 0s 9us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6227 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6398\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.00425\n",
      "Epoch 236/300\n",
      "21608/21608 [==============================] - 0s 10us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6230 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6411\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.00425 to 0.00425, saving model to ./trained_weights/model\n",
      "Epoch 237/300\n",
      "21608/21608 [==============================] - 0s 9us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6239 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6405\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.00425\n",
      "Epoch 238/300\n",
      "21608/21608 [==============================] - 0s 9us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6233 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6367\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.00425\n",
      "Epoch 239/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6218 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6384\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.00425\n",
      "Epoch 240/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6244 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6414\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.00425\n",
      "Epoch 241/300\n",
      "21608/21608 [==============================] - 0s 9us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6236 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6405\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.00425\n",
      "Epoch 242/300\n",
      "21608/21608 [==============================] - 0s 9us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6253 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6385\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.00425\n",
      "Epoch 243/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6243 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6412\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.00425 to 0.00424, saving model to ./trained_weights/model\n",
      "Epoch 244/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6262 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6395\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.00424\n",
      "Epoch 245/300\n",
      "21608/21608 [==============================] - 0s 9us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6248 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6402\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.00424\n",
      "Epoch 246/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6253 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6394\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.00424\n",
      "Epoch 247/300\n",
      "21608/21608 [==============================] - 0s 10us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6255 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6405\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.00424\n",
      "Epoch 248/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6257 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6409\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.00424\n",
      "Epoch 249/300\n",
      "21608/21608 [==============================] - 0s 9us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6254 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6395\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.00424\n",
      "Epoch 250/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6257 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6410\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.00424\n",
      "Epoch 251/300\n",
      "21608/21608 [==============================] - 0s 10us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6253 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6400\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.00424\n",
      "Epoch 252/300\n",
      "21608/21608 [==============================] - 0s 9us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6270 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6409\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.00424\n",
      "Epoch 253/300\n",
      "21608/21608 [==============================] - 0s 9us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6273 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6408\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.00424\n",
      "Epoch 254/300\n",
      "21608/21608 [==============================] - 0s 9us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6262 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6432\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.00424 to 0.00423, saving model to ./trained_weights/model\n",
      "Epoch 255/300\n",
      "21608/21608 [==============================] - 0s 10us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6263 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6411\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.00423\n",
      "Epoch 256/300\n",
      "21608/21608 [==============================] - 0s 10us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6271 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6418\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.00423\n",
      "Epoch 257/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6279 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6411\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.00423\n",
      "Epoch 258/300\n",
      "21608/21608 [==============================] - 0s 9us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6268 - val_loss: 0.0043 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6402\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.00423\n",
      "Epoch 259/300\n",
      "21608/21608 [==============================] - 0s 10us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6276 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6443\n",
      "\n",
      "Epoch 00259: val_loss improved from 0.00423 to 0.00422, saving model to ./trained_weights/model\n",
      "Epoch 260/300\n",
      "21608/21608 [==============================] - 0s 10us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6277 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6414\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.00422\n",
      "Epoch 261/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6269 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6417\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.00422\n",
      "Epoch 262/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6277 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6439\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.00422 to 0.00422, saving model to ./trained_weights/model\n",
      "Epoch 263/300\n",
      "21608/21608 [==============================] - 0s 9us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6284 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6425\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.00422\n",
      "Epoch 264/300\n",
      "21608/21608 [==============================] - 0s 11us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6285 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6428\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.00422\n",
      "Epoch 265/300\n",
      "21608/21608 [==============================] - 0s 10us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6281 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6423\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.00422\n",
      "Epoch 266/300\n",
      "21608/21608 [==============================] - 0s 9us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6280 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6409\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.00422\n",
      "Epoch 267/300\n",
      "21608/21608 [==============================] - 0s 10us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6274 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6412\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.00422\n",
      "Epoch 268/300\n",
      "21608/21608 [==============================] - 0s 10us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6282 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6416\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.00422\n",
      "Epoch 269/300\n",
      "21608/21608 [==============================] - 0s 11us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6279 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6440\n",
      "\n",
      "Epoch 00269: val_loss improved from 0.00422 to 0.00422, saving model to ./trained_weights/model\n",
      "Epoch 270/300\n",
      "21608/21608 [==============================] - 0s 10us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6277 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6443\n",
      "\n",
      "Epoch 00270: val_loss improved from 0.00422 to 0.00422, saving model to ./trained_weights/model\n",
      "Epoch 271/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6289 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6409\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.00422\n",
      "Epoch 272/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6278 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6420\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.00422\n",
      "Epoch 273/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6293 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6414\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.00422\n",
      "Epoch 274/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0043 - mean_squared_error: 0.0035 - det_coeff: 0.6290 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6420\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.00422\n",
      "Epoch 275/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6281 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6436\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.00422\n",
      "Epoch 276/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6293 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6436\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.00422\n",
      "Epoch 277/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6299 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6433\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.00422\n",
      "Epoch 278/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6281 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6435\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.00422\n",
      "Epoch 279/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6295 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6437\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.00422\n",
      "Epoch 280/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6288 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6452\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.00422 to 0.00421, saving model to ./trained_weights/model\n",
      "Epoch 281/300\n",
      "21608/21608 [==============================] - 0s 10us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6293 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6442\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.00421\n",
      "Epoch 282/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6299 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6450\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.00421\n",
      "Epoch 283/300\n",
      "21608/21608 [==============================] - 0s 10us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6304 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6422\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.00421\n",
      "Epoch 284/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6308 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6428\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.00421\n",
      "Epoch 285/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6297 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6431\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.00421\n",
      "Epoch 286/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6293 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6432\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.00421\n",
      "Epoch 287/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6298 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6436\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.00421\n",
      "Epoch 288/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6304 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6443\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.00421\n",
      "Epoch 289/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6287 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6433\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.00421\n",
      "Epoch 290/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6288 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6431\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.00421\n",
      "Epoch 291/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6299 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6444\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.00421\n",
      "Epoch 292/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6301 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6437\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.00421\n",
      "Epoch 293/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6309 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6450\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.00421\n",
      "Epoch 294/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6311 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6453\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.00421\n",
      "Epoch 295/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6308 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6432\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.00421\n",
      "Epoch 296/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6312 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6436\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.00421\n",
      "Epoch 297/300\n",
      "21608/21608 [==============================] - 0s 9us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6309 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6449\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.00421\n",
      "Epoch 298/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6295 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6450\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.00421\n",
      "Epoch 299/300\n",
      "21608/21608 [==============================] - 0s 7us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6317 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6427\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.00421\n",
      "Epoch 300/300\n",
      "21608/21608 [==============================] - 0s 8us/step - loss: 0.0042 - mean_squared_error: 0.0035 - det_coeff: 0.6308 - val_loss: 0.0042 - val_mean_squared_error: 0.0035 - val_det_coeff: 0.6447\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.00421\n"
     ]
    }
   ],
   "source": [
    "epoch = 300\n",
    "batch_size = 1000\n",
    "save_dir = './trained_weights/model'\n",
    "\n",
    "valid_loss = []\n",
    "train_loss = []\n",
    "\n",
    "model = create_model()\n",
    "save_callback = keras.callbacks.ModelCheckpoint(save_dir, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "history = model.fit(x=[dynamic_train, static_train], y=label_train, batch_size=batch_size, epochs=epoch, callbacks=[save_callback], verbose=1, validation_data=([dynamic_valid, static_valid],label_valid), shuffle=True)\n",
    "pickle.dump(history,open(r'./trained_weights/m_history','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:45.540424Z",
     "start_time": "2019-12-13T10:33:44.647784Z"
    }
   },
   "outputs": [],
   "source": [
    "save_dir = './trained_weights/'\n",
    "model_test.load_weights(save_dir+'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:46.753558Z",
     "start_time": "2019-12-13T10:33:46.193088Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "y_pred = model_test.predict([dynamic_test[:, :-1, :], static_test[:, :-1, :]])\n",
    "y_true = label_test\n",
    "\n",
    "y_pred = y_pred.flatten()\n",
    "y_true = y_true.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:33:46.769517Z",
     "start_time": "2019-12-13T10:33:46.755554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.003523\n",
      "Mean Absolute Error: 0.031801\n",
      "R2 Score: 0.613744\n",
      "Adjusted R2 Score: 0.613502\n"
     ]
    }
   ],
   "source": [
    "print('Mean Squared Error: %.6f'%sklearn.metrics.mean_squared_error(y_pred=y_pred, y_true=y_true))\n",
    "print('Mean Absolute Error: %.6f'%sklearn.metrics.mean_absolute_error(y_pred=y_pred, y_true=y_true))\n",
    "print('R2 Score: %.6f'%sklearn.metrics.r2_score(y_pred=y_pred, y_true=y_true))\n",
    "adj_r2 = 1-(1-sklearn.metrics.r2_score(y_pred=y_pred, y_true=y_true))*(len(y_pred)-1)/(len(y_pred)-5-1)\n",
    "print('Adjusted R2 Score: %.6f'%adj_r2)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
